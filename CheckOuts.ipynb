{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16(include_top = False, weights = 'imagenet')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(include_top = True, weights = 'imagenet',classes = 1000)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `array_to_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9452c5778439>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/10_left.jpeg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[0mcolor_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpil_image\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         raise ImportError('Could not import PIL.Image. '\n\u001b[0m\u001b[0;32m    497\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m    498\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `array_to_img` requires PIL."
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img_path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/10_left.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = np.array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll\n"
     ]
    }
   ],
   "source": [
    "k = \"ll\"\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `array_to_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bbb930c676de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/10_left.jpeg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[0mcolor_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpil_image\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         raise ImportError('Could not import PIL.Image. '\n\u001b[0m\u001b[0;32m    497\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m    498\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `array_to_img` requires PIL."
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "img_path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/10_left.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `array_to_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-70a614544125>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/10_left.jpeg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[0mcolor_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpil_image\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         raise ImportError('Could not import PIL.Image. '\n\u001b[0m\u001b[0;32m    497\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m    498\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `array_to_img` requires PIL."
     ]
    }
   ],
   "source": [
    "#from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "img_path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/10_left.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.Image' has no attribute 'load_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7f6c39278b70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/10_left.jpeg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'load_img'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "img_path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/10_left.jpeg'\n",
    "img = Image.load_img(img_path, target_size=(224, 224))\n",
    "x = Image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "img_path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/10_left.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "model = VGG16(include_top = True, weights = 'imagenet',classes = 1000)\n",
    "ans = list(model.predict(x))\n",
    "print(\"pred=\",ans)\n",
    "print(\"sum=\",sum(ans))\n",
    "print(\"max=\",max(ans))\n",
    "print(\"class=\",ans.index(max(ans)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kkkkk 5\n",
      "kkkklllll 2\n",
      "12\n",
      "[1 2 5 4]\n",
      "12\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x = [1,2,5,4]\n",
    "print(\"kkkkk\",max(np.array(x)))\n",
    "print(\"kkkklllll\",x.index(max(x)))\n",
    "print(sum(x))\n",
    "x = np.array(x)\n",
    "print(x)\n",
    "print(sum(x))\n",
    "print(list(x).index(max(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nparray=  [[0.01764064 0.07085883 0.74939007 0.13803808 0.02407242]]\n",
      "pred= [0.017640637, 0.07085883, 0.74939007, 0.13803808, 0.02407242]\n",
      "sum= 1.0000000353902578\n",
      "max= 0.74939007\n",
      "class= 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "img_path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/10_left.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224,3))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "model = VGG16(include_top = False, weights = 'imagenet',input_shape = (224,224,3))\n",
    "new_model = Sequential()\n",
    "new_model.add(model)\n",
    "new_model.add(Flatten())\n",
    "new_model.add(Dense(units = 16, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))\n",
    "new_model.add(Dense(units = 16, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))              \n",
    "new_model.add(Dense(units = 5))\n",
    "new_model.add(keras.layers.Activation('softmax'))\n",
    "ans = new_model.predict(x)\n",
    "\n",
    "print(\"nparray= \",ans)\n",
    "ans = list(ans[0])\n",
    "print(\"pred=\",ans)\n",
    "print(\"sum=\",sum(ans))\n",
    "print(\"max=\",max(ans))\n",
    "print(\"class=\",ans.index(max(ans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 1.6111 - acc: 0.1250 - val_loss: 1.5630 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1.6306 - acc: 0.3750 - val_loss: 1.5427 - val_acc: 0.5000\n",
      "{'val_loss': [1.5629632472991943, 1.542654037475586], 'val_acc': [0.5, 0.5], 'loss': [1.6110669076442719, 1.6305873692035675], 'acc': [0.125, 0.375]}\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "loss= 1.601369071006775\n",
      "acc= 0.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\"\"\"\n",
    "path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/'\n",
    "img_name = os.listdir(path)\n",
    "img_arr = []\n",
    "for img in img_name:\n",
    "    x = image.load_img(path+img, target_size=(224, 224,3))\n",
    "    x = image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    img_arr.append(x)\n",
    "\n",
    "img_arr = np.array(img_arr)\n",
    "labels = np.transpose(np.array([2,3,1,4,5,1,2,5,3,4]))\n",
    "\"\"\"\n",
    "x_train = np.random.random((10, 224, 224, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(5, size=(10, 1)), num_classes=5)\n",
    "model = VGG16(include_top = False, weights = 'imagenet',input_shape = (224,224,3))\n",
    "flatten_model = Sequential()\n",
    "flatten_model.add(model)\n",
    "flatten_model.add(Flatten())\n",
    "\n",
    "features_input = flatten_model.predict(x_train)\n",
    "\n",
    "new_model = Sequential()\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))              \n",
    "new_model.add(Dense(units = 5))\n",
    "new_model.add(keras.layers.Activation('softmax'))\n",
    "sgd = SGD(lr=0.001, decay=0.0, momentum=0.9,nesterov=True)\n",
    "new_model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics=['accuracy'] )\n",
    "\n",
    "training_history = new_model.fit(x = features_input, y = y_train, batch_size = 2, epochs = 2, verbose = 2, validation_split = 0.2)\n",
    "print(training_history.history)\n",
    "\n",
    "loss , accuracy = new_model.evaluate(x = features_input, y = y_train, batch_size= 2, verbose=1)\n",
    "print(\"loss=\",loss)\n",
    "print(\"acc=\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10_left.jpeg', '10_right.jpeg', '13_left.jpeg', '13_right.jpeg', '15_left.jpeg', '15_right.jpeg', '16_left.jpeg', '16_right.jpeg', '17_left.jpeg', '17_right.jpeg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "img_list = os.listdir('C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/')\n",
    "print(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/2\n",
      " - 7s - loss: 2.9052 - acc: 0.2500 - val_loss: 2.8423 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      " - 0s - loss: 3.2456 - acc: 0.1250 - val_loss: 7.4204 - val_acc: 0.5000\n",
      "{'val_loss': [2.842301845550537, 7.420437812805176], 'val_acc': [0.5, 0.5], 'loss': [2.905191272497177, 3.2456298172473907], 'acc': [0.25, 0.125]}\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "loss= 6.289057278633118\n",
      "acc= 0.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/'\n",
    "img_name = os.listdir(path)\n",
    "img_arr = np.zeros(shape=(10,224,224,3))\n",
    "i = 0\n",
    "for img in img_name:\n",
    "    x = image.load_img(path+img, target_size=(224, 224,3))\n",
    "    x = image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    img_arr[i] = x\n",
    "    i+=1\n",
    "    \n",
    "labels = keras.utils.to_categorical(np.random.randint(5, size=(10, 1)), num_classes=5)\n",
    "model = VGG16(include_top = False, weights = 'imagenet',input_shape = (224,224,3))\n",
    "flatten_model = Sequential()\n",
    "flatten_model.add(model)\n",
    "flatten_model.add(Flatten())\n",
    "\n",
    "features_input = flatten_model.predict(img_arr)\n",
    "\n",
    "new_model = Sequential()\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))              \n",
    "new_model.add(Dense(units = 5))\n",
    "new_model.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=0.0, momentum=0.9,nesterov=True)\n",
    "new_model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics=['accuracy'] )\n",
    "\n",
    "training_history = new_model.fit(x = features_input, y = labels, batch_size = 2, epochs = 2, verbose = 2, validation_split = 0.2)\n",
    "print(training_history.history)\n",
    "\n",
    "#Testing\n",
    "#return accuracy for the test data with trained weights\n",
    "loss , accuracy = new_model.evaluate(x = features_input, y = labels, batch_size= 2, verbose=1)\n",
    "print(\"loss=\",loss)\n",
    "print(\"acc=\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1000)\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "z = np.zeros(shape=(10,1000))\n",
    "print(z.shape)\n",
    "np.save(\"imagedata\",z)\n",
    "a = np.load(\"imagedata.npy\")\n",
    "print(z == a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960000.0\n"
     ]
    }
   ],
   "source": [
    "print(4*7*7*512*20000/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features shape  (10, 25088)\n",
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/'\n",
    "img_name = os.listdir(path)\n",
    "img_arr = np.zeros(shape=(10,224,224,3))\n",
    "i = 0\n",
    "for img in img_name:\n",
    "    x = image.load_img(path+img, target_size=(224, 224,3))\n",
    "    x = image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    img_arr[i] = x\n",
    "    i+=1\n",
    "    \n",
    "labels = keras.utils.to_categorical(np.random.randint(5, size=(10, 1)), num_classes=5)\n",
    "model = VGG16(include_top = False, weights = 'imagenet',input_shape = (224,224,3))\n",
    "flatten_model = Sequential()\n",
    "flatten_model.add(model)\n",
    "flatten_model.add(Flatten())\n",
    "\n",
    "features_input = flatten_model.predict(img_arr)\n",
    "print(\"Extracted features shape \",features_input.shape)\n",
    "np.save(\"imagedata\",features_input)\n",
    "reloaded_input = np.load(\"imagedata.npy\")\n",
    "print(features_input == reloaded_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 2.8176 - acc: 0.0000e+00 - val_loss: 1.5690 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1.6066 - acc: 0.1250 - val_loss: 1.7407 - val_acc: 0.0000e+00\n",
      "{'val_loss': [1.568955898284912, 1.7406628131866455], 'val_acc': [0.0, 0.0], 'loss': [2.8176134526729584, 1.6066253185272217], 'acc': [0.0, 0.125]}\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "evaluation result =  [1.8857038021087646, 0.2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/'\n",
    "img_name = os.listdir(path)\n",
    "img_arr = np.zeros(shape=(10,224,224,3))\n",
    "i = 0\n",
    "for img in img_name:\n",
    "    x = image.load_img(path+img, target_size=(224, 224,3))\n",
    "    x = image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    img_arr[i] = x\n",
    "    i+=1\n",
    "    \n",
    "labels = keras.utils.to_categorical(np.random.randint(5, size=(10, 1)), num_classes=5)\n",
    "model = VGG16(include_top = False, weights = 'imagenet',input_shape = (224,224,3))\n",
    "flatten_model = Sequential()\n",
    "flatten_model.add(model)\n",
    "flatten_model.add(Flatten())\n",
    "\n",
    "features_input = flatten_model.predict(img_arr)\n",
    "\n",
    "\n",
    "new_model = Sequential()\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))              \n",
    "new_model.add(Dense(units = 5))\n",
    "new_model.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=0.0, momentum=0.9,nesterov=True)\n",
    "new_model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics=['accuracy'] )\n",
    "\n",
    "training_history = new_model.fit(x = features_input, y = labels, batch_size = 2, epochs = 2, verbose = 2, validation_split = 0.2)\n",
    "print(training_history.history)\n",
    "\n",
    "new_model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del new_model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "new_model = load_model('my_model.h5')\n",
    "\n",
    "evaluation_result = new_model.evaluate(x = features_input, y = labels, batch_size= 2, verbose=1)\n",
    "print(\"evaluation result = \",evaluation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 2.5895 - acc: 0.1250 - val_loss: 2.2663 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      " - 0s - loss: 5.7264 - acc: 0.2500 - val_loss: 10.1087 - val_acc: 0.0000e+00\n",
      "{'val_loss': [2.266252040863037, 10.108671188354492], 'val_acc': [0.0, 0.0], 'loss': [2.589465707540512, 5.726438015699387], 'acc': [0.125, 0.25]}\n",
      "10/10 [==============================] - 0s 13ms/step\n",
      "evaluation result =  [5.4822125911712645, 0.2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/'\n",
    "img_name = os.listdir(path)\n",
    "img_arr = np.zeros(shape=(10,224,224,3))\n",
    "i = 0\n",
    "for img in img_name:\n",
    "    x = image.load_img(path+img, target_size=(224, 224,3))\n",
    "    x = image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    img_arr[i] = x\n",
    "    i+=1\n",
    "    \n",
    "labels = keras.utils.to_categorical(np.random.randint(5, size=(10, 1)), num_classes=5)\n",
    "model = VGG16(include_top = False, weights = 'imagenet',input_shape = (224,224,3))\n",
    "flatten_model = Sequential()\n",
    "flatten_model.add(model)\n",
    "flatten_model.add(Flatten())\n",
    "\n",
    "features_input = flatten_model.predict(img_arr)\n",
    "\n",
    "\n",
    "new_model = Sequential()\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))              \n",
    "new_model.add(Dense(units = 5))\n",
    "new_model.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=0.0, momentum=0.9,nesterov=True)\n",
    "new_model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics=['accuracy'] )\n",
    "\n",
    "training_history = new_model.fit(x = features_input, y = labels, batch_size = 2, epochs = 2, verbose = 2, validation_split = 0.2)\n",
    "print(training_history.history)\n",
    "\n",
    "new_model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "new_model.save_weights('my_model_weights.h5')\n",
    "new_model.load_weights('my_model_weights.h5')\n",
    "del new_model  # deletes the existing model\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "new_model = load_model('my_model.h5')\n",
    "\n",
    "evaluation_result = new_model.evaluate(x = features_input, y = labels, batch_size= 2, verbose=1)\n",
    "print(\"evaluation result = \",evaluation_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features shape  (10, 25088)\n"
     ]
    }
   ],
   "source": [
    "#Extraction of features from freezed (non-trainable) CNN layers\n",
    "\n",
    "#import keras,numpy,os libraries\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#reading images from specified path,converting it to numpy array with images size of (224,224,3)\n",
    "path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/'\n",
    "img_name = os.listdir(path)\n",
    "img_arr = np.zeros(shape=(10,224,224,3))\n",
    "i = 0\n",
    "for img in img_name:\n",
    "    x = image.load_img(path+img, target_size=(224, 224,3))\n",
    "    x = image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    img_arr[i] = x\n",
    "    i+=1\n",
    "\n",
    "#loading weights without fc and softmax layers for Transfer learning.\n",
    "model = VGG16(include_top = False, weights = 'imagenet',input_shape = (224,224,3))\n",
    "flatten_model = Sequential()\n",
    "flatten_model.add(model)\n",
    "#flatten the last max pool layer outputs (last CNN layer output)\n",
    "flatten_model.add(Flatten())\n",
    "\n",
    "#extract features (convolutional autoencoder)\n",
    "features_input = flatten_model.predict(img_arr)\n",
    "#saving CNN outputs in a local file on disk to load later\n",
    "print(\"Extracted features shape \",features_input.shape)\n",
    "np.save(\"imagedata\",features_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/2\n",
      " - 1s - loss: 2.5528 - acc: 0.2500 - val_loss: 1.8516 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      " - 0s - loss: 1.6699 - acc: 0.3750 - val_loss: 1.8888 - val_acc: 0.0000e+00\n",
      "{'val_loss': [1.8515524864196777, 1.888837218284607], 'val_acc': [0.0, 0.0], 'loss': [2.5527948141098022, 1.669904351234436], 'acc': [0.25, 0.375]}\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "loss= 1.7325010895729065\n",
      "acc= 0.3\n"
     ]
    }
   ],
   "source": [
    "#Training classifier network\n",
    "\n",
    "#import keras,numpy,os libraries\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "#reloading CNN outputs compressed image data  from file\n",
    "features_input = np.load(\"imagedata.npy\")\n",
    "\n",
    "#Converting labels to categorial one hot encoding\n",
    "labels = keras.utils.to_categorical(np.random.randint(5, size=(10, 1)), num_classes=5)\n",
    "\n",
    "#Adding classifier neural network (Dense + Softmax)\n",
    "new_model = Sequential()\n",
    "#add a fc1 layer with 8 output neurons and a dropout layer1\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))\n",
    "#add a fc2 layer with 8 output neurons and a dropout layer2\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))\n",
    "#adding a softmax layer with 5 classes\n",
    "new_model.add(Dense(units = 5))\n",
    "new_model.add(keras.layers.Activation('softmax'))\n",
    "#configures the model for training\n",
    "sgd = SGD(lr=0.001, decay=0.0, momentum=0.9,nesterov=True)\n",
    "new_model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics=['accuracy'] )\n",
    "\n",
    "#train the model for given number of epochs\n",
    "training_history = {}\n",
    "try:\n",
    "    training_history = new_model.fit(x = features_input, y = labels, batch_size = 2, epochs = 2, verbose = 2, validation_split = 0.2)\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "finally:\n",
    "    print(training_history.history)  #validation accuracy and loss, training accuracy and loss\n",
    "    new_model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "    new_model.save_weights('my_model_weights.h5') #creates a HDF5 'my_model_weights.h5' weight file\n",
    "#End of training and va;idation   \n",
    "\n",
    "#Testing\n",
    "#return accuracy for the test data with trained weights\n",
    "try:\n",
    "    loss , accuracy = new_model.evaluate(x = features_input, y = labels, batch_size= 2, verbose=1)\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "finally:\n",
    "    print(\"loss=\",loss)\n",
    "    print(\"acc=\",accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction =  [[0.04260045 0.12288517 0.1491383  0.67477304 0.01060303]]\n",
      "sum of predictions = 0.9999999916180968\n",
      "max prediction value= 0.67477304\n",
      "class the image predicted to = 3\n"
     ]
    }
   ],
   "source": [
    "#prediction of new images from trained model\n",
    "\n",
    "#import keras,numpy,os libraries\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "img_path = 'C:/Users/Nagaraj G/Desktop/DR_Reference/data/sample/10_left.jpeg'\n",
    "img_arr =  np.zeros(shape=(1,224,224,3))\n",
    "img = image.load_img(img_path, target_size=(224, 224,3))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "img_arr[0] = x\n",
    "\n",
    "#Extract the features from image needed for classifier neural net\n",
    "model = VGG16(include_top = False, weights = 'imagenet',input_shape = (224,224,3))\n",
    "flatten_model = Sequential()\n",
    "flatten_model.add(model)\n",
    "flatten_model.add(Flatten())\n",
    "features_input = flatten_model.predict(img_arr)\n",
    "\n",
    "trainedModel = load_model('my_model.h5')\n",
    "ans = trainedModel.predict(features_input)\n",
    "\n",
    "print(\"Prediction = \",ans)\n",
    "ans = list(ans[0])\n",
    "print(\"sum of predictions =\",sum(ans))\n",
    "print(\"max prediction value=\",max(ans))\n",
    "print(\"class the image predicted to =\",ans.index(max(ans)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "val_acc = [78.7320921421051025, 82.0478668212890625]\n",
    "acc = [64.53234,78.7765433]\n",
    "plt.plot(val_acc)\n",
    "plt.plot(acc)\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 5.0267 - acc: 0.2500 - val_loss: 6.6633 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      " - 0s - loss: 4.4667 - acc: 0.2500 - val_loss: 8.0672 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 8.8624 - acc: 0.2500 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 4.4283 - acc: 0.1250 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 3.0212 - acc: 0.2500 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 3.4175 - acc: 0.2500 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 4.8324 - acc: 0.2500 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 3.2159 - acc: 0.2500 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 6.8444 - acc: 0.2500 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.5969 - acc: 0.2500 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "{'val_loss': [6.6633100509643555, 8.067163467407227, 8.05904769897461, 8.05904769897461, 8.05904769897461, 8.05904769897461, 8.05904769897461, 8.05904769897461, 8.05904769897461, 8.05904769897461], 'val_acc': [0.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'loss': [5.026704788208008, 4.4666872918605804, 8.862386703491211, 4.428269624710083, 3.021209806203842, 3.4175136983394623, 4.832353740930557, 3.2158835530281067, 6.844359397888184, 1.5968590676784515], 'acc': [0.25, 0.25, 0.25, 0.125, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 780us/step\n",
      "loss= 11.282666778564453\n",
      "acc= 0.3\n"
     ]
    }
   ],
   "source": [
    "#prediction of new images from trained model\n",
    "\n",
    "#import keras,numpy,os, matplotlib libraries\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "#reloading CNN outputs compressed image data  from file\n",
    "features_input = np.load(\"imagedata.npy\")\n",
    "\n",
    "#Converting labels to categorial one hot encoding\n",
    "labels = keras.utils.to_categorical(np.random.randint(5, size=(10, 1)), num_classes=5)\n",
    "\n",
    "#Adding classifier neural network (Dense + Softmax)\n",
    "new_model = Sequential()\n",
    "#add a fc1 layer with 8 output neurons and a dropout layer1\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))\n",
    "#add a fc2 layer with 8 output neurons and a dropout layer2\n",
    "new_model.add(Dense(units = 8, activation = 'relu', kernel_initializer='uniform'))\n",
    "new_model.add(Dropout(rate = 0.5, noise_shape=None, seed=None))\n",
    "#adding a softmax layer with 5 classes\n",
    "new_model.add(Dense(units = 5))\n",
    "new_model.add(keras.layers.Activation('softmax'))\n",
    "#configures the model for training\n",
    "sgd = SGD(lr=0.001, decay=0.0, momentum=0.9,nesterov=True)\n",
    "new_model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics=['accuracy'] )\n",
    "\n",
    "#train the model for given number of epochs\n",
    "training_history = {}\n",
    "try:\n",
    "    training_history = new_model.fit(x = features_input, y = labels, batch_size = 2, epochs = 10, verbose = 2, validation_split = 0.2)\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "finally:\n",
    "    print(training_history.history)  #validation accuracy and loss, training accuracy and loss\n",
    "    new_model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "    new_model.save_weights('my_model_weights.h5') #creates a HDF5 'my_model_weights.h5' weight file\n",
    "#End of training and va;idation   \n",
    "\n",
    "#plotting accuracy of training and validation\n",
    "plt.plot(training_history.history['acc'])\n",
    "plt.plot(training_history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#plotting loss of training and validation\n",
    "plt.plot(training_history.history['loss'])\n",
    "plt.plot(training_history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Testing\n",
    "#return accuracy for the test data with trained weights\n",
    "try:\n",
    "    loss , accuracy = new_model.evaluate(x = features_input, y = labels, batch_size= 2, verbose=1)\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "finally:\n",
    "    print(\"loss=\",loss)\n",
    "    print(\"acc=\",accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
